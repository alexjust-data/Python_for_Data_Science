{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"float: right; width: 50%;\">\n",
    "    <p style=\"margin: 0; text-align:right;\">Python en Ciencia de Datos Aplicada</p>\n",
    "    <p style=\"margin: 0; text-align:right; padding-button: 100px;\">Preprocesamiento de datos\n",
    "</p>\n",
    "</div>\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"width:100%;\">&nbsp;</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "32FBeM9lnkYP"
   },
   "source": [
    "# Preprocesamiento de datos\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_KHv9akunkYP"
   },
   "source": [
    "Esta unidad presenta las principales herramientas de preprocesamiento de datos en Python. Veremos cómo utilizar la librería [pandas](http://pandas.pydata.org/), que ya hemos introducido en los módulos anteriores, para preprocesar datos, y también introduciremos el uso de una nueva librería, [scikit-learn](http://scikit-learn.org)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9eU9JyM5nkYQ"
   },
   "source": [
    "## Introducción\n",
    "\n",
    "Los datos adquiridos del mundo real acostumbran a ser incompletos y a contener ruido e inconsistencias. Por este motivo, surge la necesidad del preprocesamiento de datos.\n",
    "\n",
    "El **preprocesamiento de datos** es el conjunto de técnicas que permite convertir un conjunto de datos en bruto en un conjunto de datos que pueda ser usado por un algoritmo de minería de datos. El objetivo principal del preprocesamiento de datos es mejorar la calidad de los datos utilizados por las técnicas de minería de datos, de manera que estas puedan operar con más facilidad.\n",
    "\n",
    "Dentro de las técnicas de preprocesamiento de datos, distinguimos dos grandes grupos: **preparación** de los datos y **reducción** de los datos.\n",
    "\n",
    "![](img/Preprocesamiento-de-datos.png)\n",
    "\n",
    "La **integración** de los datos se centra en la recolección de todos los datos necesarios para el análisis (que a menudo proceden de fuentes distintas) en un único conjunto. La integración de datos debe afrontar problemas como la eliminación de atributos redundantes, la detección de tuplas duplicadas y la identificación de inconsistencias. Tanto los atributos redundantes como las tuplas duplicadas hacen aumentar el espacio de almacenamiento y el tiempo de cómputo necesarios para tratarlos y, además, pueden ser fuente de inconsistencias. \n",
    "\n",
    "Una vez se dispone de un conjunto de datos integrados, es necesario aplicar un proceso de **limpieza**. Este proceso se encarga de tratar los valores perdidos y datos erróneos (o datos con ruido), que pueden aparecer a causa de errores en la entrada de datos, la transmisión, o los propios sistemas de procesamiento de datos. \n",
    "\n",
    "En ocasiones los datos contienen atributos que tienen sentido en el dominio en el que fueron recogidos pero no son suficientemente buenos para construir modelos. En estos casos, se suele aplicar un proceso de **normalización** que transforme los atributos originales (por ejemplo, cambiando la escala en la que se representan).\n",
    "\n",
    "Adicionalmente, se pueden realizar otro tipo de **transformaciones** en los datos, de manera que se generen nuevos atributos a partir de los existentes. Así, por ejemplo, puede ser beneficioso generar un nuevo atributo que agregue información contenida en otros atributos o bien transformar un atributo nominal a varios atributos binarios (lo que permitirá aplicar modelos que solo sepan trabajar con atributos numéricos).\n",
    "\n",
    "Cada vez más nos encontramos con conjuntos de datos de gran tamaño, con millones de muestras y miles de atributos, a los cuales queremos aplicar técnicas de minería de datos. Aplicar los algoritmos de minería de datos directamente sobre estos conjuntos de datos es poco eficiente y, muy a menudo, incluso inviable. En estos casos, se aplican técnicas de **reducción** de datos, que reducen el tamaño del conjunto de datos a procesar intentando mantener la información que contenía el conjunto de datos original.\n",
    "\n",
    "El proceso de **reducción de dimensiones** reduce el número de atributos del conjunto de datos. Generalmente se siguen dos estrategias distintas para reducir el número de dimensiones de un conjunto de datos: la selección de características, que escoge un subconjunto de entre el conjunto de características disponibles; y la extracción de características, que construye un conjunto de características derivadas de las originales.\n",
    "\n",
    "Mientras que los procesos de reducción de dimensiones reducen el número de características del conjunto de datos, los procesos de **reducción de muestras** se centran en reducir el número de muestras o ejemplos que serán utilizadas por el algoritmo de minería de datos.\n",
    "\n",
    "Por último, las técnicas de **discretización** de datos permiten reducir el número de valores de un atributo continuo dividiendo el rango de valores posibles del atributo en intervalos y reemplazando los valores continuos por una etiqueta que representa el intervalo en el cual se encuentran."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJ2-jGjpnkYR"
   },
   "source": [
    "## Preprocesamiento de datos en Python\n",
    "\n",
    "En este módulo trabajaremos con la librería [pandas](http://pandas.pydata.org/), que ya hemos introducido en módulos anteriores, y [scikit-learn](http://scikit-learn.org), una nueva librería que presentamos en este módulo. Scikit-learn es una librería de aprendizaje automático de Python que nos ofrece herramientas y implementaciones de algoritmos para minería y análisis de datos. En la propia web de scikit-learn podéis encontrar la [documentación completa](http://scikit-learn.org/stable/documentation.html) de la librería.\n",
    "\n",
    "Este Notebook contiene ejemplos concretos de técnicas que pueden aplicarse para preprocesar datos para cada uno de los grupos de técnicas descritos en la introducción del módulo (en la xwiki asociada). Es importante destacar que se han seleccionado únicamente algunas técnicas dentro de cada grupo para presentar ejemplos del tipo de transformaciones que se realizan pero, en la práctica, el conjunto de técnicas que se aplican en el preprocesamiento de los datos es mucho más amplio. \n",
    "\n",
    "En este Notebook veremos cómo aplicar diferentes técnicas de preprocesamiento de datos sobre un conjunto de datos metereológicos de la ciudad de Pequín. El *dataset* original puede encontrarse en el siguiente [repositorio de Machine Learning de la UC Irvine](http://archive.ics.uci.edu/ml/datasets/Beijing+PM2.5+Data#), aunque para las actividades utilizaremos una variante modificada del mismo que nos permitirá practicar un conjunto más amplio de técnicas. Podéis encontrar una pequeña descripción de los atributos del conjunto de datos siguiendo el enlace anterior.\n",
    "\n",
    "En primer lugar, cargamos el conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "executionInfo": {
     "elapsed": 912,
     "status": "error",
     "timestamp": 1607623974521,
     "user": {
      "displayName": "Alex Rodríguez",
      "photoUrl": "",
      "userId": "00870778593581408894"
     },
     "user_tz": -60
    },
    "id": "3Gunzh3g1RhF",
    "outputId": "26f59fdd-72f3-4da3-fdef-6f9915226b54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "43824\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>pm2.5</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>PRES</th>\n",
       "      <th>cbwd</th>\n",
       "      <th>Iws</th>\n",
       "      <th>Is</th>\n",
       "      <th>Ir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>jan</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>Nw</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>jan</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>nw</td>\n",
       "      <td>4.92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>jan</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>nw</td>\n",
       "      <td>6.71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>jan</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>9.84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>jan</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-20</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>nW</td>\n",
       "      <td>12.97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No  year month  day  hour  pm2.5  DEWP  TEMP    PRES cbwd    Iws  Is  Ir\n",
       "0   1  2010   jan    1     0    NaN   -21 -11.0  1021.0   Nw   1.79   0   0\n",
       "1   2  2010   jan    1     1    NaN   -21 -12.0  1020.0   nw   4.92   0   0\n",
       "2   3  2010   jan    1     2    NaN   -21 -11.0  1019.0   nw   6.71   0   0\n",
       "3   4  2010   jan    1     3    NaN   -21 -14.0  1019.0   NW   9.84   0   0\n",
       "4   5  2010   jan    1     4    NaN   -20 -12.0  1018.0   nW  12.97   0   0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importamos la librería pandas.\n",
    "import pandas as pd\n",
    "\n",
    "# Cargamos los datos del fichero \"weather_dataset_edited.csv\" en un dataframe.\n",
    "data = pd.read_csv(\"data/weather_dataset_edited.csv\")\n",
    "\n",
    "# Mostramos una descripción básica de los datos cargados.\n",
    "print(type(data))\n",
    "print(len(data))\n",
    "data.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1xaf0AcsnkYT"
   },
   "source": [
    "## Integración de datos\n",
    "\n",
    "El conjunto de datos ha sido creado con la colaboración de diferentes personas. Aunque todas ellas anotaban la misma información, lo cierto es que utilizaron una nomenclatura distinta para describir la dirección del viento. Veamos cómo podemos unificar la nomenclatura usada por todos ellos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 738,
     "status": "ok",
     "timestamp": 1607623705507,
     "user": {
      "displayName": "Alex Rodríguez",
      "photoUrl": "",
      "userId": "00870778593581408894"
     },
     "user_tz": -60
    },
    "id": "QlohGk-dnkYT",
    "outputId": "607c2236-ca87-4eb4-f433-6c83ff3f3931"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NE', 'NW', 'Nw', 'SE', 'Se', 'nW', nan, 'ne', 'nw', 'sE', 'se'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizamos las diferentes abreviaturas utilizadas.\n",
    "set(data[\"cbwd\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "tuKI-ffynkYT"
   },
   "outputs": [],
   "source": [
    "'''.loc[] Acceda a un grupo de filas y columnas por etiqueta (s) o una matriz booleana.\n",
    "   .loc[] se basa principalmente en etiquetas, pero también se puede utilizar con una matriz booleana.'''\n",
    "\n",
    "# Unificamos la nomenclatura para usar únicamente mayúsculas.\n",
    "data.loc[ data.cbwd == \"ne\", \"cbwd\"] = \"NE\"\n",
    "data.loc[(data.cbwd == \"Nw\") | (data.cbwd == \"nW\") | (data.cbwd == \"nw\"), \"cbwd\"] = \"NW\"\n",
    "data.loc[(data.cbwd == \"Se\") | (data.cbwd == \"sE\") | (data.cbwd == \"se\"), \"cbwd\"] = \"SE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GC0spmk6nkYU"
   },
   "source": [
    "Notad que usamos el operador `.loc`, que habíamos visto en el módulo 4 (en las explicaciones sobre la librería pandas) para filtrar las filas que cumplen una característica concreta (por ejemplo, para la primera sentencia, que tienen el valor 'ne' en el campo `cbwd`) y luego seleccionamos únicamente la columna `cbwd` para poder asignarle el nuevo valor (en este caso, 'NE')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "hgA_az2VnkYU"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NE', 'NW', 'SE', nan}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''https://docs.python.org/3/tutorial/datastructures.html#sets\n",
    "   set() -> A set is an unordered collection with no duplicate elements. \n",
    "            Basic uses include membership testing and eliminating duplicate entries. \n",
    "            Set objects also support mathematical operations like union, intersection, \n",
    "            difference, and symmetric difference.'''\n",
    "\n",
    "# Comprobamos que la sustitución se haya realizado correctamente.\n",
    "set(data[\"cbwd\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ook2UiXenkYU"
   },
   "source": [
    "Además, sabemos que normalmente la temperatura se tomaba con un termómetro configurado para usar el sistema métrico internacional, por lo que esta se encuentra expresada en grados Celsius. Sin embargo, durante el año 2011 se estuvieron tomando las mediciones con otro termómetro configurado con grados Farenheit, por lo que las muestras de ese año se encuentran expresadas en °F. Veamos cómo podemos unificar las mediciones de temperatura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "0CklnNW8nkYU"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEMP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>11.632420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>54.617534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>11.967441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>12.399201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>13.679566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           TEMP\n",
       "year           \n",
       "2010  11.632420\n",
       "2011  54.617534\n",
       "2012  11.967441\n",
       "2013  12.399201\n",
       "2014  13.679566"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np             \n",
    "\n",
    "# Visualizamos la media anual de las temperaturas.\n",
    "grouped = data.groupby(\"year\")      #Agrupar DataFrame usando un asignador o por una serie de columnas.\n",
    "\n",
    "'''Me daba error porque debían haber valores que no eran numéricos en la columna TEMP,\n",
    "   estoy agrupando los años con la columna TEMP. \n",
    "   https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_numeric.html\n",
    "   He tenido que buscar/aplicar la siguiente linea:'''\n",
    "\n",
    "data['TEMP'] = pd.to_numeric(data['TEMP'], errors = 'coerce')\n",
    "\n",
    "grouped.aggregate({\"TEMP\": np.mean})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_bS4us2znkYU"
   },
   "source": [
    "Fijaos como, efectivamente, la media del año 2011 es mucho más alta que la del resto de años."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "15tCjEcvnkYV"
   },
   "outputs": [],
   "source": [
    "# Definimos una función que convierte grados Fahrenheit en grados Celsius.\n",
    "def fahrenheit_to_celsius(x):\n",
    "    return (x-32)*5/9\n",
    "\n",
    "# Sustituimos los valores de las temperaturas del año 2011 por el resultado de aplicar la función\n",
    "# 'fahrenheit_to_celsius' al valor actual.\n",
    "data.loc[data.year == 2011, \"TEMP\"] = data[data.year == 2011][\"TEMP\"].apply(fahrenheit_to_celsius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "3hYE5F_SnkYV"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEMP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>11.632420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>12.565297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>11.967441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>12.399201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>13.679566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           TEMP\n",
       "year           \n",
       "2010  11.632420\n",
       "2011  12.565297\n",
       "2012  11.967441\n",
       "2013  12.399201\n",
       "2014  13.679566"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comprobamos que los cambios realizados han tenido efecto.\n",
    "grouped.aggregate({\"TEMP\": np.mean})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o_dOKcuwnkYV"
   },
   "source": [
    "## Transformación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jaW4Le7dnkYV"
   },
   "source": [
    "Los atributos `month` y `cbwd` contienen cadenas de caracteres como valores y representan variables categóricas, por lo que algunos tipos de algoritmos de minería de datos no podrán trabajar con ellas. Por ello, las transformaremos en un conjunto de atributos binarios (un atributo para cada categoría posible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "lVhRwHWtnkYV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No', 'year', 'month', 'day', 'hour', 'pm2.5', 'DEWP', 'TEMP', 'PRES', 'cbwd', 'Iws', 'Is', 'Ir']\n"
     ]
    }
   ],
   "source": [
    "# Mostramos el conjunto de atributos original.\n",
    "print(list(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "4I2IfSIenkYV"
   },
   "outputs": [],
   "source": [
    "# Creamos nuevos atributos binarios para las categorías utilizadas en las columnas \"month\" y \"cbwd\".\n",
    "'''.get_dummies() -> Convierta la variable categórica en variables ficticias / indicadoras.'''\n",
    "''' dummy_na -> bool, predeterminado Falso\n",
    "                Agregue una columna para indicar los NaN, si se ignoran los NaN falsos.'''\n",
    "\n",
    "data_trans = pd.get_dummies(data, columns=[\"month\", \"cbwd\"], dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "lSQ4yMQGnkYW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No', 'year', 'day', 'hour', 'pm2.5', 'DEWP', 'TEMP', 'PRES', 'Iws', 'Is', 'Ir', 'month_apr', 'month_aug', 'month_dec', 'month_feb', 'month_jan', 'month_jul', 'month_jun', 'month_mar', 'month_may', 'month_nov', 'month_oct', 'month_sept', 'month_nan', 'cbwd_NE', 'cbwd_NW', 'cbwd_SE', 'cbwd_nan']\n"
     ]
    }
   ],
   "source": [
    "# Mostramos el conjunto de atributos después de la transformación.\n",
    "print(list(data_trans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KG0jtrsrnkYW"
   },
   "source": [
    "Podemos ver un ejemplo de cómo se han transformado los valores observando algunas muestras concretas. Así, para las muestras entre las posiciones diez y veinte y la columna `cbwd`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "jfFCZXajnkYW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cbwd\n",
      "10   NW\n",
      "11   NW\n",
      "12   NW\n",
      "13   NW\n",
      "14   NW\n",
      "15  NaN\n",
      "16   NW\n",
      "17   NW\n",
      "18   NE\n",
      "19   NW\n",
      "20  NaN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cbwd_NE</th>\n",
       "      <th>cbwd_NW</th>\n",
       "      <th>cbwd_SE</th>\n",
       "      <th>cbwd_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cbwd_NE  cbwd_NW  cbwd_SE  cbwd_nan\n",
       "10        0        1        0         0\n",
       "11        0        1        0         0\n",
       "12        0        1        0         0\n",
       "13        0        1        0         0\n",
       "14        0        1        0         0\n",
       "15        0        0        0         1\n",
       "16        0        1        0         0\n",
       "17        0        1        0         0\n",
       "18        1        0        0         0\n",
       "19        0        1        0         0\n",
       "20        0        0        0         1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostramos el valor de la columna \"cbwd\" original para las muestras entre las posiciones diez y veinte.\n",
    "print(data.loc[10:20, [\"cbwd\"]])\n",
    "\n",
    "# Mostramos los valores de las nuevas columnas \"cbwd_NE\", \"cbwd_NW\", \"cbwd_SE\", \"cbwd_nan\"\n",
    "# para las muestras entre las posiciones diez y veinte.\n",
    "data_trans.loc[10:20, [\"cbwd_NE\", \"cbwd_NW\", \"cbwd_SE\", \"cbwd_nan\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gugki0FvnkYW"
   },
   "source": [
    "## Limpieza de datos\n",
    "\n",
    "Uno de los problemas que se tratan en la limpieza de datos es el tratamiento de valores perdidos. Existen múltiples estrategias para tratar con estos valores, desde directamente eliminar las muestras que contienen algún valor perdido hasta sustituir los valores perdidos por algún otro valor (por ejemplo, para atributos numéricos, la media del atributo en el resto de muestras). Veamos un ejemplo de sustitución de valores perdidos por la media del atributo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JhgpZXQ3nkYW"
   },
   "source": [
    "En primer lugar, identificamos los atributos que tienen algún valor NaN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "nMSHdNqAnkYW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No            False\n",
      "year          False\n",
      "day           False\n",
      "hour          False\n",
      "pm2.5          True\n",
      "DEWP          False\n",
      "TEMP          False\n",
      "PRES          False\n",
      "Iws           False\n",
      "Is            False\n",
      "Ir            False\n",
      "month_apr     False\n",
      "month_aug     False\n",
      "month_dec     False\n",
      "month_feb     False\n",
      "month_jan     False\n",
      "month_jul     False\n",
      "month_jun     False\n",
      "month_mar     False\n",
      "month_may     False\n",
      "month_nov     False\n",
      "month_oct     False\n",
      "month_sept    False\n",
      "month_nan     False\n",
      "cbwd_NE       False\n",
      "cbwd_NW       False\n",
      "cbwd_SE       False\n",
      "cbwd_nan      False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "'''The any() function returns True if any item in an iterable are true, otherwise it returns False.\n",
    "   If the iterable object is empty, the any() function will return False.'''\n",
    "'''.isnull(obj) Detect missing values for an array-like object.'''\n",
    "\n",
    "# Definimos función que nos retorna valor booleano indicando si algún valor de la serie es NaN.\n",
    "def any_is_null(x):\n",
    "    return any(pd.isnull(x))\n",
    "\n",
    "print(data_trans.apply(any_is_null)) # Aplicamos función any_is_null a cada columna del dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LRy4BKRKnkYX"
   },
   "source": [
    "Notad que aunque la columna `cbwd` original contenía valores perdidos, después de la transformación ya no los tenemos, ya que estos se encuentran representados con valores binarios en la columna `cbwd_nan`. Así, únicamente será necesario tratar los valores perdidos de la columna `pm2.5`.\n",
    "\n",
    "Procedemos a sustituir los valores perdidos de la columa `pm2.5` por la media de la columna utilizando la librería sklearn (aunque también podríamos utilizar las funciones de indexación de pandas para conseguir el mismo objetivo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "NEoeIlL-nkYX"
   },
   "outputs": [],
   "source": [
    "# Importamos Imputer del módulo de preprocesamiento de la librería sklearn.\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Sustituiremos los valores perdidos por la media de la columna \n",
    "imp = SimpleImputer(strategy='mean')\n",
    "\n",
    "'''fit_transform significa hacer un cálculo y luego hacer una transformación (digamos, calcular las medias \n",
    "   de las columnas a partir de algunos datos y luego reemplazar los valores faltantes). \n",
    "   Entonces, para el conjunto de entrenamiento, debe calcular y realizar la transformación.'''\n",
    "\n",
    "'''numpy.ravel( a , orden = 'C' )Devuelve una matriz plana contigua.\n",
    "   Se devuelve una matriz 1-D que contiene los elementos de la entrada. '''\n",
    "\n",
    "# Aplicamos la transformación a la columna pm2.5.\n",
    "data_trans[\"pm2.5\"] = imp.fit_transform(data_trans[[\"pm2.5\"]]).ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "5KuUwyDMnkYX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No            False\n",
      "year          False\n",
      "day           False\n",
      "hour          False\n",
      "pm2.5         False\n",
      "DEWP          False\n",
      "TEMP          False\n",
      "PRES          False\n",
      "Iws           False\n",
      "Is            False\n",
      "Ir            False\n",
      "month_apr     False\n",
      "month_aug     False\n",
      "month_dec     False\n",
      "month_feb     False\n",
      "month_jan     False\n",
      "month_jul     False\n",
      "month_jun     False\n",
      "month_mar     False\n",
      "month_may     False\n",
      "month_nov     False\n",
      "month_oct     False\n",
      "month_sept    False\n",
      "month_nan     False\n",
      "cbwd_NE       False\n",
      "cbwd_NW       False\n",
      "cbwd_SE       False\n",
      "cbwd_nan      False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "'''One alternative to using a loop to iterate over a DataFrame is to use the pandas .apply() method. \n",
    "   This function acts as a map() function in Python. \n",
    "   It takes a function as an input and applies this function to an entire DataFrame.\n",
    "   https://www.datacamp.com/community/tutorials/pandas-apply\n",
    "   https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.apply.html'''\n",
    "\n",
    "# Comprobamos que se han eliminado los valores perdidos.\n",
    "print(data_trans.apply(any_is_null))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AQNEbs5KnkYX"
   },
   "source": [
    "## Normalización de datos\n",
    "\n",
    "Una de las alternativas para normalizar los datos consiste en centrar los valores para que la media del atributo se encuentre cercana a cero y escalarlos para que la varianza sea 1. Veamos cómo realizar este proceso sobre el atributo que contiene la presión atmosférica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "GXeHZXg-nkYX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    43824.000000\n",
       "mean      1016.447654\n",
       "std         10.268698\n",
       "min        991.000000\n",
       "25%       1008.000000\n",
       "50%       1016.000000\n",
       "75%       1025.000000\n",
       "max       1046.000000\n",
       "Name: PRES, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observamos los estadísticos básicos originales del atributo \"PRES\".\n",
    "data_trans[\"PRES\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "v3idCuiEnkYX"
   },
   "outputs": [],
   "source": [
    "'''El sklearn.preprocessingpaquete proporciona varias funciones de utilidad comunes y clases de transformadores \n",
    "   para cambiar los vectores de características sin procesar en una representación que sea más adecuada \n",
    "   para los estimadores posteriores. En general, los algoritmos de aprendizaje se benefician de la \n",
    "   estandarización del conjunto de datos. Si algunos valores atípicos están presentes en el conjunto, \n",
    "   los transformadores o escaladores robustos son más apropiados.'''\n",
    "\n",
    "# Importamos StandardScaler del módulo de preprocesamiento de la librería sklearn.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "'''Vuelv aplicar el método para \"numerizar\" todos los elementos de la columna'''\n",
    "data_trans[\"PRES\"] = pd.to_numeric(data_trans[\"PRES\"], errors= 'coerce')\n",
    "\n",
    "'''StandardScaler() -> Estandarizar características eliminando la media y escalando a la varianza de la unidad'''\n",
    "# Utilizamos el StandardScaler de sklearn para normalizar los valores del atributo \"PRES\".\n",
    "data_trans.loc[:, [\"PRES\"]] = StandardScaler().fit_transform(data_trans.loc[:, [\"PRES\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ohPKGsP5nkYY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4.382400e+04\n",
       "mean     2.664485e-15\n",
       "std      1.000011e+00\n",
       "min     -2.478206e+00\n",
       "25%     -8.226701e-01\n",
       "50%     -4.359456e-02\n",
       "75%      8.328654e-01\n",
       "max      2.877939e+00\n",
       "Name: PRES, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observamos los estadísticos básicos del atributo \"PRES\" después de la transformación.\n",
    "data_trans[\"PRES\"].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V7u25qHjnkYY"
   },
   "source": [
    "Notad como, efectivamente, la media se aproxima ahora al valor 0, y la desviación, a 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wV9QygfYnkYY"
   },
   "source": [
    "## Reducción de dimensiones\n",
    "\n",
    "Una opción sencilla para reducir dimensiones consiste en seleccionar un conjunto de características de interés. Podemos realizar esta selección de manera sencilla gracias a las funciones que disponemos sobre los *dataframes* de pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "_SyzjiC0nkYY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No', 'year', 'day', 'hour', 'pm2.5', 'DEWP', 'TEMP', 'PRES', 'Iws', 'Is', 'Ir', 'month_apr', 'month_aug', 'month_dec', 'month_feb', 'month_jan', 'month_jul', 'month_jun', 'month_mar', 'month_may', 'month_nov', 'month_oct', 'month_sept', 'month_nan', 'cbwd_NE', 'cbwd_NW', 'cbwd_SE', 'cbwd_nan']\n"
     ]
    }
   ],
   "source": [
    "# Mostramos los atributos actuales.\n",
    "print(list(data_trans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "dXL1ryEmnkYY"
   },
   "outputs": [],
   "source": [
    "# Eliminamos el atributo \"DEWP\".\n",
    "data_trans = data_trans.drop(\"DEWP\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Q-UhSDW9nkYY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No', 'year', 'day', 'hour', 'pm2.5', 'TEMP', 'PRES', 'Iws', 'Is', 'Ir', 'month_apr', 'month_aug', 'month_dec', 'month_feb', 'month_jan', 'month_jul', 'month_jun', 'month_mar', 'month_may', 'month_nov', 'month_oct', 'month_sept', 'month_nan', 'cbwd_NE', 'cbwd_NW', 'cbwd_SE', 'cbwd_nan']\n"
     ]
    }
   ],
   "source": [
    "# Mostramos los atributos después del cambio.\n",
    "print(list(data_trans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sTvMRhoinkYY"
   },
   "source": [
    "Un grupo de técnicas de reducción de dimensiones muy desarrollado se centra en la extracción de características. Aunque conceptualmente estos procesos se escapan de este curso introductorio, lo cierto es que es fácil aplicar estas técnicas con sklearn. El lector interesado puede consultar [los ejemplos](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#examples-using-sklearn-decomposition-pca) de la propia documentación de sklearn. \"https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#examples-using-sklearn-decomposition-pca\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OBt3JppEnkYZ"
   },
   "source": [
    "## Reducción de muestras\n",
    "\n",
    "Una alternativa sencilla para realizar una reducción de las muestras disponibles consiste en seleccionar de manera aleatoria uniforme un subconjunto de muestras del *dataset*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "24BZ-oodnkYZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43824\n"
     ]
    }
   ],
   "source": [
    "# Mostramos el número de muestras original.\n",
    "print(len(data_trans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "DtSNoss6nkYZ"
   },
   "outputs": [],
   "source": [
    "# Seleccionamos un 25 % de las muestras de manera aleatoria.\n",
    "sampled_data = data_trans.sample(frac=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "87QbV18ynkYZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10956\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>year</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>pm2.5</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>PRES</th>\n",
       "      <th>Iws</th>\n",
       "      <th>Is</th>\n",
       "      <th>Ir</th>\n",
       "      <th>...</th>\n",
       "      <th>month_mar</th>\n",
       "      <th>month_may</th>\n",
       "      <th>month_nov</th>\n",
       "      <th>month_oct</th>\n",
       "      <th>month_sept</th>\n",
       "      <th>month_nan</th>\n",
       "      <th>cbwd_NE</th>\n",
       "      <th>cbwd_NW</th>\n",
       "      <th>cbwd_SE</th>\n",
       "      <th>cbwd_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16392</th>\n",
       "      <td>16393</td>\n",
       "      <td>2011</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>314.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.027634</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40003</th>\n",
       "      <td>40004</td>\n",
       "      <td>2014</td>\n",
       "      <td>25</td>\n",
       "      <td>19</td>\n",
       "      <td>44.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>-1.212208</td>\n",
       "      <td>27.27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35869</th>\n",
       "      <td>35870</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.930250</td>\n",
       "      <td>80.03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16332</th>\n",
       "      <td>16333</td>\n",
       "      <td>2011</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>34.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.151174</td>\n",
       "      <td>33.97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33405</th>\n",
       "      <td>33406</td>\n",
       "      <td>2013</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>13.86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          No  year  day  hour  pm2.5  TEMP      PRES    Iws  Is  Ir  ...  \\\n",
       "16392  16393  2011   15     0  314.0   2.0  1.027634   0.45   0   0  ...   \n",
       "40003  40004  2014   25    19   44.0  31.0 -1.212208  27.27   0   0  ...   \n",
       "35869  35870  2014    3    13    6.0   1.0  0.930250  80.03   0   0  ...   \n",
       "16332  16333  2011   12    12   34.0  16.0  0.151174  33.97   0   0  ...   \n",
       "33405  33406  2013   23    21   18.0   9.0  0.832865  13.86   0   0  ...   \n",
       "\n",
       "       month_mar  month_may  month_nov  month_oct  month_sept  month_nan  \\\n",
       "16392          0          0          1          0           0          0   \n",
       "40003          0          0          0          0           0          0   \n",
       "35869          0          0          0          0           0          0   \n",
       "16332          0          0          1          0           0          0   \n",
       "33405          0          0          0          1           0          0   \n",
       "\n",
       "       cbwd_NE  cbwd_NW  cbwd_SE  cbwd_nan  \n",
       "16392        0        0        0         1  \n",
       "40003        0        0        1         0  \n",
       "35869        0        1        0         0  \n",
       "16332        0        1        0         0  \n",
       "33405        0        1        0         0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostramos el número de muestras seleccionado.\n",
    "print(len(sampled_data))\n",
    "\n",
    "# Mostramos las cinco primeras muestras seleccionadas.\n",
    "sampled_data.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gOuO6y-ynkYZ"
   },
   "source": [
    "Notad que el *dataframe* conserva el número de atributos original, pero solo contiene un 25 % de las muestras originales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "monHkIsBnkYZ"
   },
   "source": [
    "## Discretización\n",
    "\n",
    "En ocasiones nos interesará convertir un atributo continuo en uno de discreto. Una manera de hacerlo es divir el espacio de posibles valores que toma el atributo en `n` _bins_ o intervalos del mismo tamaño y asignar cada muestra al intervalo al que pertenece. Veamos un ejemplo discretizando el atributo `Iws` en cinco intervalos del mismo tamaño.\n",
    "\n",
    "Un '''atributo continuo''' tiene un número infinito de valores posibles. Es representado por números reales o de punto flotante. Se pueden obtener tan precisos como sea el instrumento de medición. Los atributos categóricos o cualitativos siempre son discretos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "MyWOBiVznkYZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    43824.000000\n",
       "mean        23.889140\n",
       "std         50.010635\n",
       "min          0.450000\n",
       "25%          1.790000\n",
       "50%          5.370000\n",
       "75%         21.910000\n",
       "max        585.600000\n",
       "Name: Iws, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observamos los estadísticos básicos del atributo \"Iws\".\n",
    "data_trans[\"Iws\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "1o9koUdcnkYa"
   },
   "outputs": [],
   "source": [
    "'''pd.cut() -> Agrupa los valores en intervalos discretos.'''\n",
    "\n",
    "# Creamos un nuevo atributo \"Iws_disc\" que contiene la discretización de \"Iws\".\n",
    "data_trans[\"Iws_disc\"] = pd.cut(data_trans[\"Iws\"], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "vpk9H1FLnkYa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iws</th>\n",
       "      <th>Iws_disc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>80.90</td>\n",
       "      <td>(-0.135, 117.48]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>90.73</td>\n",
       "      <td>(-0.135, 117.48]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>100.56</td>\n",
       "      <td>(-0.135, 117.48]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>108.61</td>\n",
       "      <td>(-0.135, 117.48]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>117.55</td>\n",
       "      <td>(117.48, 234.51]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>127.38</td>\n",
       "      <td>(117.48, 234.51]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>136.32</td>\n",
       "      <td>(117.48, 234.51]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>145.26</td>\n",
       "      <td>(117.48, 234.51]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>152.41</td>\n",
       "      <td>(117.48, 234.51]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>159.56</td>\n",
       "      <td>(117.48, 234.51]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>165.37</td>\n",
       "      <td>(117.48, 234.51]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Iws          Iws_disc\n",
       "80   80.90  (-0.135, 117.48]\n",
       "81   90.73  (-0.135, 117.48]\n",
       "82  100.56  (-0.135, 117.48]\n",
       "83  108.61  (-0.135, 117.48]\n",
       "84  117.55  (117.48, 234.51]\n",
       "85  127.38  (117.48, 234.51]\n",
       "86  136.32  (117.48, 234.51]\n",
       "87  145.26  (117.48, 234.51]\n",
       "88  152.41  (117.48, 234.51]\n",
       "89  159.56  (117.48, 234.51]\n",
       "90  165.37  (117.48, 234.51]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizamos el contenido de los atributos \"Iws\" y \"Iws_disc\" para un subconjunto de muestras \n",
    "# para observar el resultado.\n",
    "data_trans.loc[80:90, [\"Iws\", \"Iws_disc\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4bNUFQQJnkYa"
   },
   "source": [
    "Por defecto la función `cut` utiliza el intervalo como valor del nuevo atributo. Podemos asignar valores arbitrarios al nuevo atributo, por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "SPvcOJaKnkYa"
   },
   "outputs": [],
   "source": [
    "# Designamos cinco nombres para los intervalos.\n",
    "group_names = ['Very Low', 'Low', 'Medium', 'High', 'Very High']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "aX549tmXnkYa"
   },
   "outputs": [],
   "source": [
    "# Creamos un nuevo atributo \"Iws_disc_named\" discretizando de nuevo \"Iws\" con 5 intervalos\n",
    "# del mismo tamaño pero usando ahora las etiquetas definidas.\n",
    "data_trans[\"Iws_disc_named\"] = pd.cut(data_trans[\"Iws\"], 5, labels = group_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "yG89L6renkYa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iws</th>\n",
       "      <th>Iws_disc</th>\n",
       "      <th>Iws_disc_named</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>80.90</td>\n",
       "      <td>(-0.135, 117.48]</td>\n",
       "      <td>Very Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>90.73</td>\n",
       "      <td>(-0.135, 117.48]</td>\n",
       "      <td>Very Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>100.56</td>\n",
       "      <td>(-0.135, 117.48]</td>\n",
       "      <td>Very Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>108.61</td>\n",
       "      <td>(-0.135, 117.48]</td>\n",
       "      <td>Very Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>117.55</td>\n",
       "      <td>(117.48, 234.51]</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>127.38</td>\n",
       "      <td>(117.48, 234.51]</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>136.32</td>\n",
       "      <td>(117.48, 234.51]</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>145.26</td>\n",
       "      <td>(117.48, 234.51]</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>152.41</td>\n",
       "      <td>(117.48, 234.51]</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>159.56</td>\n",
       "      <td>(117.48, 234.51]</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>165.37</td>\n",
       "      <td>(117.48, 234.51]</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Iws          Iws_disc Iws_disc_named\n",
       "80   80.90  (-0.135, 117.48]       Very Low\n",
       "81   90.73  (-0.135, 117.48]       Very Low\n",
       "82  100.56  (-0.135, 117.48]       Very Low\n",
       "83  108.61  (-0.135, 117.48]       Very Low\n",
       "84  117.55  (117.48, 234.51]            Low\n",
       "85  127.38  (117.48, 234.51]            Low\n",
       "86  136.32  (117.48, 234.51]            Low\n",
       "87  145.26  (117.48, 234.51]            Low\n",
       "88  152.41  (117.48, 234.51]            Low\n",
       "89  159.56  (117.48, 234.51]            Low\n",
       "90  165.37  (117.48, 234.51]            Low"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizamos el contenido de los atributos \"Iws\", \"Iws_disc\" y \"Iws_disc_named\" \n",
    "# para un subconjunto de muestras para observar el resultado.\n",
    "data_trans.loc[80:90, [\"Iws\", \"Iws_disc\", \"Iws_disc_named\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8l-5CJLvnkYb"
   },
   "source": [
    "## Bibliografía\n",
    "\n",
    "* Documentación del paquete preprocessing de la librería Sklearn: http://scikit-learn.org/stable/modules/preprocessing.html\n",
    "* Tutorial sobre escalado con la librería Sklearn: https://scikit-learn.org/0.18/auto_examples/preprocessing/plot_robust_scaling.html\n",
    "* Libro sobre técnicas de preprocesamiento de datos: García, Salvador; Luengo, Julián; Herrera, Francisco. (2015). Fecha preprocessing in data mining. Nueva York: Springer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "o_dOKcuwnkYV",
    "gugki0FvnkYW",
    "AQNEbs5KnkYX",
    "wV9QygfYnkYY",
    "OBt3JppEnkYZ",
    "monHkIsBnkYZ",
    "8l-5CJLvnkYb"
   ],
   "name": "prog_datasci_6_preproc.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python(base)",
   "language": "python",
   "name": "anaconda-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
